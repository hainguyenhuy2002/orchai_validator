{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Blockchain\\data\\orai\\orchai_validator\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labeling.upload import ETLProcessor, get_spark, get_batch_intervals, sampling\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"config/local_full.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = get_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7062873 7064871\n",
      "7064313 7065351\n"
     ]
    }
   ],
   "source": [
    "from labeling.upload import get_batch_intervals\n",
    "\n",
    "vote_proposed_win_size = config.hp.etl.vote_proposed_win_size\n",
    "combine_win_size = config.hp.etl.combine_win_size\n",
    "label_win_size = config.hp.etl.label_win_size\n",
    "batch_size = config.hp.upload.batch_size\n",
    "\n",
    "for bs, be in get_batch_intervals(\n",
    "    start_block=7063372,\n",
    "    global_end_block=7065370,\n",
    "    batch_size=batch_size,\n",
    "    vote_proposed_win_size=vote_proposed_win_size,\n",
    "    combine_win_size=combine_win_size,\n",
    "    label_win_size=label_win_size,\n",
    "    min_block=7049472\n",
    "):\n",
    "    print(bs, be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7064871 - 7062873 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully queried data from database\n"
     ]
    }
   ],
   "source": [
    "df = sampling(spark, config, 7062873, 7064871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"block_height\").count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Successfully converted voting_power_score column\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Successfully converted commission_score column\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Successfully converted self_bonded_score column\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Successfully converted vote_propose_score column\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Sucessfully converted final_score\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Sucessfully combine data\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Sucessfully shifting data\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dff = ETLProcessor.data_scoring(df, **config.hp.etl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- operator_address: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- voting_power_score: double (nullable = true)\n",
      " |-- tokens_proportion: decimal(38,10) (nullable = true)\n",
      " |-- commission_rate: double (nullable = true)\n",
      " |-- self_bonded: decimal(38,4) (nullable = true)\n",
      " |-- self_bonded_score: double (nullable = true)\n",
      " |-- delegator_shares: decimal(38,4) (nullable = true)\n",
      " |-- tokens: decimal(38,4) (nullable = true)\n",
      " |-- commission_score: double (nullable = true)\n",
      " |-- block_height: integer (nullable = true)\n",
      " |-- vote_propose_score: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.groupBy(\"block_height\").count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "dp = dff.groupBy(\"block_height\").count().pandas_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\MiniConda3\\envs\\py38\\lib\\site-packages\\pyspark\\pandas\\generic.py:647: UserWarning: We recommend using `DataFrame.to_numpy()` instead.\n",
      "  warnings.warn(\"We recommend using `{}.to_numpy()` instead.\".format(type(self).__name__))\n",
      "d:\\Apps\\MiniConda3\\envs\\py38\\lib\\site-packages\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: `to_numpy` loads all data into the driver's memory. It should only be used if the resulting NumPy ndarray is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    }
   ],
   "source": [
    "d = dp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = d[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({20: 71})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "cnt = Counter(np.diff(bh))\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7063372, 7064792)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh[0], bh[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7063372, 7064792\n",
    "7062873, 7064871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7063372 - 7062873 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7064871 - 7064792 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "953727d1e95b678a3946b8bfc3d5a175ea50e205ad779370d1fb67fabbb85d7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
